import random
from flask import Blueprint, request, jsonify, session
import os, tempfile
from config import client

speech_bp = Blueprint("speech", __name__)

# üé§ Speech-to-Text (—Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è)
@speech_bp.route("/speech-to-text", methods=["POST"])
def speech_to_text():
    if "file" not in request.files:
        return jsonify({"error": "–§–∞–π–ª –Ω–µ –Ω–∞–¥—ñ—Å–ª–∞–Ω–∏–π"}), 400

    audio_file = request.files["file"]

    try:
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è –ø–æ —ñ–º–µ–Ω—ñ —Ñ–∞–π–ª—É
        ext = ".webm"
        filename = audio_file.filename.lower()
        if filename.endswith(".m4a") or filename.endswith(".mp4"):
            ext = ".mp4"
        elif filename.endswith(".wav"):
            ext = ".wav"

        # –¢–∏–º—á–∞—Å–æ–≤–æ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ —É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—ñ
        with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:
            audio_file.save(tmp.name)
            with open(tmp.name, "rb") as f:
                transcript = client.audio.transcriptions.create(
                    model="gpt-4o-mini-transcribe",
                    file=f,
                    prompt="–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á –≥–æ–≤–æ—Ä–∏—Ç—å –ª–∏—à–µ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é"
                )
        os.unlink(tmp.name)

        text = transcript.text.strip()
        return jsonify({"text": text})

    except Exception as e:
        print(f"[STT ERROR] {str(e)}")
        return jsonify({"error": "–ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è"}), 500


# üîä Text-to-Speech (–æ–∑–≤—É—á–∫–∞)
# üîä Text-to-Speech (–æ–∑–≤—É—á–∫–∞)
@speech_bp.route("/speak", methods=["POST"])
def speak():
    text = request.json.get("text", "").strip()
    if not text:
        return jsonify({"error": "–ü–æ—Ä–æ–∂–Ω—ñ–π —Ç–µ–∫—Å—Ç"}), 400
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —Ü–µ exam –∫–∞—Ç–µ–≥–æ—Ä—ñ—è
    category = session.get("category")
    if category != "exam":
        return jsonify({"error": "–û–∑–≤—É—á–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç—ñ–ª—å–∫–∏ –≤ —Ä–µ–∂–∏–º—ñ –µ–∫–∑–∞–º–µ–Ω—É"}), 403
    
    # –û—Ç—Ä–∏–º—É—î–º–æ ID –∫–ª—ñ—î–Ω—Ç–∞
    client_id = session.get("current_situation_id")
    
    # –ê–ö–¢–£–ê–õ–¨–ù–Ü –ì–û–õ–û–°–ò (–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ OpenAI)
    FEMALE_VOICES = ["nova", "shimmer", "fable", "verse", "coral"]
    MALE_VOICES = ["alloy", "echo", "onyx", "sage"]
    FEMALE_IDS = {3, 8, 20, 34, 35, 46, 47, 49, 58, 59, 61}

    # –Ø–∫—â–æ –≥–æ–ª–æ—Å —â–µ –Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Ü—ñ—î—ó —Å–µ—Å—ñ—ó - –≤–∏–±–∏—Ä–∞—î–º–æ –π–æ–≥–æ
    if "voice" not in session:
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –≥–æ–ª–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤—ñ ID –∫–ª—ñ—î–Ω—Ç–∞
        if client_id in FEMALE_IDS:
            voice = random.choice(FEMALE_VOICES)
        else:
            voice = random.choice(MALE_VOICES)
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≥–æ–ª–æ—Å —É —Å–µ—Å—ñ—ó –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
        session["voice"] = voice
        print(f"[TTS] –û–±—Ä–∞–Ω–æ –≥–æ–ª–æ—Å: {voice} –¥–ª—è –∫–ª—ñ—î–Ω—Ç–∞ ID: {client_id} (exam —Ä–µ–∂–∏–º)")
    else:
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≤–∂–µ –∑–±–µ—Ä–µ–∂–µ–Ω–∏–π –≥–æ–ª–æ—Å
        voice = session["voice"]
        print(f"[TTS] –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–±–µ—Ä–µ–∂–µ–Ω–∏–π –≥–æ–ª–æ—Å: {voice} (exam —Ä–µ–∂–∏–º)")

    try:
        response = client.audio.speech.create(
            model="tts-1",
            voice=voice,
            input=text
        )
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
            tmp.write(response.read())
            tmp_path = tmp.name
        with open(tmp_path, "rb") as f:
            audio_data = f.read()
        os.unlink(tmp_path)
        return audio_data, 200, {
            "Content-Type": "audio/mpeg",
            "Content-Disposition": f"inline; filename={voice}.mp3"
        }
    except Exception as e:
        print(f"[TTS ERROR] {str(e)}")
        return jsonify({"error": "–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∞—É–¥—ñ–æ"}), 500
